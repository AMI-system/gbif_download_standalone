{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is taken after the occurrence.txt file has been extracted from the dwca zip file, and saved as a reduced CSV file.\n",
    "\n",
    "This script will load the occurrence csv file, split it by \"acceptedTaxonKey\" and save each as a separate CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure loggingg\n",
    "logging.basicConfig(filename='split_log.log', level=logging.INFO,\n",
    "                    format='%(asctime)s [%(levelname)s] - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "if sys.platform.startswith(\"linux\"):\n",
    "    data_dir = \"/bask/projects/v/vjgo8416-amber/data/gbif-species-trainer-AMI-fork/\"\n",
    "elif sys.platform == \"darwin\":\n",
    "    data_dir = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data/\"\n",
    "else:\n",
    "    print(\"Not linux or mac!\")\n",
    "\n",
    "\n",
    "save_folder = \"occurrence_dataframes\"\n",
    "\n",
    "save_dir = os.path.join(data_dir,save_folder)\n",
    "\n",
    "# If save_dir doesn't exist, create it \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "filename = \"lepidoptera\"\n",
    "\n",
    "occ_df_path = os.path.join(data_dir,\"dwca_files\",\"occurrence_\"+filename+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/8z6pr__14lq801rwlk2hx9r40000gr/T/ipykernel_99931/3960989757.py:6: DtypeWarning: Columns (1,3,4,5,6,7,8,9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  occ_df = pd.read_csv(occ_df_path, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs['parse_dates'] = True\n",
    "kwargs['on_bad_lines'] = \"skip\"\n",
    "\n",
    "occ_df = pd.read_csv(occ_df_path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric acceptedTaxonKey rows\n",
    "def is_number(x):\n",
    "    try:\n",
    "        # Check for NaN\n",
    "        if pd.isna(x):\n",
    "            return False\n",
    "        # Try converting the element to a float.\n",
    "        float(x)  \n",
    "        return True  # If conversion is successful, it's a number or a number string.\n",
    "    except ValueError:  # If conversion fails, it's not a number string.\n",
    "        return False\n",
    "    except TypeError:  # If type conversion is not possible (e.g., for NaNs), also not considered as a number.\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_type(x):\n",
    "    if pd.isna(x):\n",
    "        return 'missing'\n",
    "    elif isinstance(x, bool):\n",
    "        return 'bool'\n",
    "    else:\n",
    "        return type(x).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptedTaxonKey\n",
      "int        70060192\n",
      "float      15957971\n",
      "str          163836\n",
      "missing          49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "type_counts_custom_pre = occ_df[\"acceptedTaxonKey\"].apply(custom_type).value_counts()\n",
    "print(type_counts_custom_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = occ_df[\"acceptedTaxonKey\"].apply(is_number)\n",
    "\n",
    "occ_df = occ_df[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptedTaxonKey\n",
      "int      70060192\n",
      "float    15957971\n",
      "str        163831\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "type_counts_custom_post = occ_df[\"acceptedTaxonKey\"].apply(custom_type).value_counts()\n",
    "print(type_counts_custom_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptedTaxonKey\n",
       "float    86181994\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conver all strings to floats\n",
    "# Custom function to convert strings to floats when possible\n",
    "def convert_str_to_float(x):\n",
    "    if isinstance(x, str):  # Check if x is a string\n",
    "        try:\n",
    "            return float(x)  # Try to convert x to a float\n",
    "        except ValueError:  # Handle exception if conversion is not possible\n",
    "            return x  # Return the original string if conversion fails\n",
    "    else:\n",
    "        return x  # Return x unchanged if it's not a string\n",
    "\n",
    "# Applying the custom function to the 'mixed_col'\n",
    "occ_df[\"acceptedTaxonKey\"] = occ_df[\"acceptedTaxonKey\"].apply(convert_str_to_float)\n",
    "\n",
    "# Pring type counts\n",
    "occ_df[\"acceptedTaxonKey\"].apply(custom_type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check if any floats have non-0 fractions\n",
    "float_rows_with_fraction = occ_df[\n",
    "    occ_df['acceptedTaxonKey'].apply(\n",
    "        lambda x: isinstance(x, float) and (x != int(x))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with non-0 fraction\n",
    "mask = ~occ_df[\"acceptedTaxonKey\"].apply(lambda x: isinstance(x, float) and x != int(x))\n",
    "\n",
    "occ_df = occ_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to integer\n",
    "occ_df[\"acceptedTaxonKey\"] = occ_df[\"acceptedTaxonKey\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptedTaxonKey\n",
      "int    86181993\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Last check of types\n",
    "type_counts_custom_post2 = occ_df[\"acceptedTaxonKey\"].apply(custom_type).value_counts()\n",
    "print(type_counts_custom_post2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try saving as dataframes\n",
    "groups = occ_df.groupby(\"acceptedTaxonKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272182"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_group(group):\n",
    "    \n",
    "    group_name, group_df = group\n",
    "    filename = f\"{group_name}.csv\"\n",
    "    \n",
    "    try:\n",
    "        group_df.to_csv(os.path.join(save_dir, filename), index=False)\n",
    "        logging.info(f\"Saved {filename} with {len(group_df)} rows\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Couldn't save {filename}: {str(e)}\")\n",
    "\n",
    "groups = list(occ_df.groupby(\"acceptedTaxonKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multi-threading\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(save_group, groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif_download_standalone (Conda)",
   "language": "python",
   "name": "sys_gbif_download_standalone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
