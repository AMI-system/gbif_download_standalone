{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is taken after the occurrence.txt file has been extracted from the dwca zip file, and saved as a reduced CSV file.\n",
    "\n",
    "This script will load the occurrence csv file, split it by \"acceptedTaxonKey\" and save each as a separate CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "data_dir = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data/\"\n",
    "# data_dir = \"/bask/projects/v/vjgo8416-amber/data/gbif-species-trainer-AMI-fork/\"\n",
    "\n",
    "save_folder = \"occurrence_dataframes\"\n",
    "\n",
    "save_dir = os.path.join(data_dir,save_folder)\n",
    "\n",
    "# If save_dir doesn't exist, create it \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "filename = \"Sesiidae\"\n",
    "\n",
    "occ_df_path = os.path.join(data_dir,\"dwca_files\",\"occurrence_\"+filename+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs['parse_dates'] = True\n",
    "kwargs['on_bad_lines'] = \"skip\"\n",
    "\n",
    "occ_df = pd.read_csv(occ_df_path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric acceptedTaxonKey rows\n",
    "def is_number(x):\n",
    "    try:\n",
    "        # Check for NaN\n",
    "        if pd.isna(x):\n",
    "            return False\n",
    "        # Try converting the element to a float.\n",
    "        float(x)  \n",
    "        return True  # If conversion is successful, it's a number or a number string.\n",
    "    except ValueError:  # If conversion fails, it's not a number string.\n",
    "        return False\n",
    "    except TypeError:  # If type conversion is not possible (e.g., for NaNs), also not considered as a number.\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = occ_df[\"acceptedTaxonKey\"].apply(is_number)\n",
    "\n",
    "occ_df_preprocessed = occ_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try saving as dataframes\n",
    "groups = occ_df_preprocessed.groupby(\"acceptedTaxonKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_group(group):\n",
    "    \n",
    "    group_name, group_df = group\n",
    "    filename = f\"{group_name}.csv\"\n",
    "    \n",
    "    try:\n",
    "        group_df.to_csv(os.path.join(save_dir, filename), index=False)\n",
    "        # print(f\"Success for {group_name}\")\n",
    "    except:\n",
    "        print(f\"Couldn't save {group_name}\")\n",
    "\n",
    "groups = list(occ_df_preprocessed.groupby(\"acceptedTaxonKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multi-threading\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(save_group, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name, group_df in groups:\n",
    "    filename = f'{group_name}.csv'\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        group_df.to_csv(os.path.join(save_dir,filename), index=False)\n",
    "        \n",
    "    except:\n",
    "        print(f\"Couldn't save {group_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif_download_standalone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
