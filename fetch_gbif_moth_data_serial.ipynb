{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import urllib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from dwca.read import DwCAReader\n",
    "\n",
    "import logging\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "# data_dir = \"/bask/homes/r/rybf4168/vjgo8416-amber/data/gbif-species-trainer-AMI-fork\"\n",
    "data_dir = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data\"\n",
    "\n",
    "species_checklist_path = os.path.join(home_dir,\"species_checklists\",\"uksi-moths-keys-nodup-small.csv\")\n",
    "\n",
    "dwca_occurrence_df_path = os.path.join(data_dir,\"occurrence_dataframes\")\n",
    "\n",
    "dwca_multimedia_df_path = os.path.join(data_dir,\"dwca_files\",\"multimedia_lepidoptera.csv\")\n",
    "\n",
    "output_location_path = os.path.join(data_dir,\"gbif_images\",\"sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the multimedia file\n",
    "media_df = pd.read_csv(dwca_multimedia_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read species list\n",
    "moth_data = pd.read_csv(species_checklist_path)\n",
    "\n",
    "taxon_keys = list(moth_data[\"accepted_taxon_key\"])\n",
    "taxon_keys = [int(taxon) for taxon in taxon_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_meta_data(data: pd.DataFrame):\n",
    "    \"\"\"returns the relevant metadata for a GBIF observation\"\"\"\n",
    "\n",
    "    fields = [\n",
    "        \"decimalLatitude\",\n",
    "        \"decimalLongitude\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"species\",\n",
    "        \"acceptedScientificName\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"datasetName\",\n",
    "        \"taxonID\",\n",
    "        \"acceptedTaxonKey\",\n",
    "        \"lifeStage\",\n",
    "        \"basisOfRecord\",\n",
    "    ]\n",
    "\n",
    "    meta_data = {}\n",
    "\n",
    "    for field in fields:\n",
    "        if pd.isna(data[field]):\n",
    "            meta_data[field] = \"NA\"\n",
    "        else:\n",
    "            meta_data[field] = data[field]\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for count, i_taxon_key in enumerate(taxon_keys):\n",
    "    \n",
    "#     fetch_image_data(i_taxon_key)\n",
    "    \n",
    "# print(\"Finished downloading for the given list!\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_data(i_taxon_key: int):\n",
    "    global skip_non_adults\n",
    "    \n",
    "    species_meta_data = {}\n",
    "\n",
    "    # get taxa information specific to the species\n",
    "    taxon_data = moth_data[moth_data[\"accepted_taxon_key\"] == i_taxon_key]\n",
    "\n",
    "    family_name         = taxon_data[\"family_name\"].item()\n",
    "    genus_name          = taxon_data[\"genus_name\"].item()\n",
    "    species_name        = taxon_data[\"gbif_species_name\"].item()\n",
    "    write_location      = os.path.join(output_location_path,family_name,genus_name,species_name)\n",
    "\n",
    "    # Read the occurrence dataframe\n",
    "    if os.path.isfile(os.path.join(dwca_occurrence_df_path,\n",
    "                                    str(i_taxon_key) + \".csv\")): \n",
    "        i_occ_df = pd.read_csv(os.path.join(dwca_occurrence_df_path,\n",
    "                                            str(i_taxon_key) + \".csv\"))\n",
    "        total_occ = len(i_occ_df)\n",
    "        print(f\"Downloading for {species_name}\", flush=True) \n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"No occurrence csv file found for {species_name}, taxon key {i_taxon_key}\"\n",
    "            )\n",
    "        return\n",
    "\n",
    "    # creating hierarchical folder structure for image storage\n",
    "    if not os.path.isdir(write_location):\n",
    "        try:\n",
    "            os.makedirs(write_location)\n",
    "        except:\n",
    "            print(f\"Could not create the directory for {write_location}\", flush=True)\n",
    "            return\n",
    "        \n",
    "    image_count = 0\n",
    "\n",
    "    if total_occ != 0:\n",
    "        # print(f\"{species_name} has some occurrences\")\n",
    "        \n",
    "        for idx, row in i_occ_df.iterrows():\n",
    "            \n",
    "            if skip_non_adults:\n",
    "                \n",
    "                if (not pd.isna(row[\"lifeStage\"])) & (row[\"lifeStage\"] != \"Adult\"):\n",
    "                    \n",
    "                    # print(\"Life stage is\", row[\"lifeStage\"], \"skipping...\")\n",
    "                \n",
    "                    continue\n",
    "            \n",
    "            obs_id = row[\"id\"]\n",
    "\n",
    "            # check occurrence entry in media dataframe\n",
    "            try:\n",
    "                media_entry = media_df.loc[media_df[\"coreid\"] == obs_id]\n",
    "\n",
    "                if not media_entry.empty:\n",
    "                    # print(f\"{species_name} has some media\")\n",
    "                          \n",
    "                    if len(media_entry) > 1:  # multiple images for an observation\n",
    "                        media_entry = media_entry.iloc[0, :]\n",
    "                        image_url = media_entry[\"identifier\"]\n",
    "                    else:\n",
    "                        image_url = media_entry[\"identifier\"].item()\n",
    "                else:\n",
    "                    \n",
    "                    # print(f\"{species_name} has NO media\")\n",
    "                    continue\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e, flush=True)\n",
    "                continue\n",
    "\n",
    "            # download image\n",
    "            if os.path.isfile(write_location + \"/\" + str(obs_id) + \".jpg\"):\n",
    "                image_count += 1\n",
    "            else:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(\n",
    "                        image_url, write_location + \"/\" + str(obs_id) + \".jpg\"\n",
    "                    )\n",
    "                    image_count += 1\n",
    "                    # m_data = fetch_meta_data(row)\n",
    "                    # meta_data[str(obs_id) + \".jpg\"] = m_data\n",
    "                except:\n",
    "                    print(f\"Error downloading URL: '{image_url}'\")\n",
    "                    continue\n",
    "                \n",
    "            # Get meta data for this occurrence\n",
    "            occ_meta_data = fetch_meta_data(row)\n",
    "            species_meta_data[str(obs_id) + \".jpg\"] = occ_meta_data\n",
    "            \n",
    "            if image_count >= max_data_sp:\n",
    "                break\n",
    "            \n",
    "        # Dump metadata\n",
    "        with open(write_location + \"/\" + \"meta_data.json\", \"w\") as outfile:\n",
    "            json.dump(species_meta_data, outfile)            \n",
    "            \n",
    "    print(f\"Downloading complete for {species_name} with {image_count} images.\",\n",
    "            flush=True)\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, define a function that manages the parallel execution:\n",
    "def download_images_concurrently(taxon_keys,use_parallel,n_workers):\n",
    "    \n",
    "    begin = time.time()\n",
    "\n",
    "    \n",
    "    if use_parallel:\n",
    "        with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "\n",
    "            # You can use the executor to parallelize your function call:\n",
    "            results = list(executor.map(fetch_image_data, taxon_keys))\n",
    "    \n",
    "    else:\n",
    "       \n",
    "        for i_taxon_key in taxon_keys:\n",
    "            print(f\"Calling for {i_taxon_key}\")\n",
    "            fetch_image_data(i_taxon_key)\n",
    "   \n",
    "\n",
    "    end = time.time()\n",
    "            \n",
    "    print(\"Finished downloading for the given list! Time taken:\", \n",
    "          round(end - begin), \n",
    "          \"seconds\",\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger():\n",
    "    \n",
    "    # Specify the directory where you want to save the log files\n",
    "    log_dir = \"log_files\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # Use the timestamp string to create a unique filename for the log file\n",
    "    timestamp    = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_filename = os.path.join(log_dir, f'download_log_{timestamp}.log')\n",
    "    \n",
    "    # Get the root logger\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # If logger has handlers, clear them\n",
    "    for handler in logger.handlers[:]:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Configure the logger\n",
    "    logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading for Pyropteron chrysidiformis\n",
      "Downloading for Paranthrene tabaniformis\n",
      "Downloading for Bembecia ichneumoniformis\n",
      "Downloading for Pennisetia hylaeiformis\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Larva skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Downloading for Sesia apiformis\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'https://static.inaturalist.org/photos/151585772/original.jpg'\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Unknown skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Egg skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Unknown skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Unknown skipping...\n",
      "Downloading complete for Pyropteron chrysidiformis with 100 images.\n",
      "Downloading for Sesia bembeciformis\n",
      "Life stage is Pupa skipping...\n",
      "Life stage is Larva skipping...\n",
      "Life stage is Nymph skipping...\n",
      "Life stage is Nymph skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Larva skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'nan'\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Nymph skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'https://static.inaturalist.org/photos/29045889/original.jpg'\n",
      "Error downloading URL: 'https://static.inaturalist.org/photos/29045553/original.jpg'\n",
      "Life stage is Larva skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'nan'\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Unknown skipping...\n",
      "Life stage is Unknown skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'nan'\n",
      "Error downloading URL: 'nan'\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Error downloading URL: 'https://static.inaturalist.org/photos/146061903/original.jpg'\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n",
      "Life stage is Imago skipping...\n"
     ]
    }
   ],
   "source": [
    "# Setup logger\n",
    "setup_logger()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Start the run\n",
    "n_workers = 5    \n",
    "use_parallel = True\n",
    "max_data_sp = 100\n",
    "skip_non_adults = True\n",
    "\n",
    "# Lastly, call the function with your taxon keys:\n",
    "download_images_concurrently(taxon_keys,use_parallel,n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_taxon_key = 1940838\n",
    "\n",
    "i_occ_df = pd.read_csv(os.path.join(dwca_occurrence_df_path,\n",
    "                                    str(i_taxon_key) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_occ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif_download_standalone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
