{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import urllib\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "from dwca.read import DwCAReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "species_checklist_path = os.path.join(home_dir,\"species_checklists\",\"uksi-moths-keys-nodup-small.csv\")\n",
    "\n",
    "dwca_occurrence_df_path = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data/occurrence_dataframes/\"\n",
    "\n",
    "dwca_multimedia_df_path = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data/dwca_files/multimedia_lepidoptera.csv\"\n",
    "\n",
    "output_location_path = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data/gbif_images/sandbox/\"\n",
    "\n",
    "max_data_sp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the multimedia file\n",
    "media_df = pd.read_csv(dwca_multimedia_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read species list\n",
    "moth_data = pd.read_csv(species_checklist_path)\n",
    "\n",
    "taxon_keys = list(moth_data[\"accepted_taxon_key\"])\n",
    "taxon_keys = [int(taxon) for taxon in taxon_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, i_taxon_key in enumerate(taxon_keys):\n",
    "    \n",
    "    # get taxa information specific to the species\n",
    "    taxon_data = moth_data[moth_data[\"accepted_taxon_key\"] == i_taxon_key]\n",
    "\n",
    "    family_name         = taxon_data[\"family_name\"].item()\n",
    "    genus_name          = taxon_data[\"genus_name\"].item()\n",
    "    species_name        = taxon_data[\"gbif_species_name\"].item()\n",
    "    write_location      = os.path.join(output_location_path,family_name,genus_name,species_name)\n",
    " \n",
    "    # Read the occurrence dataframe\n",
    "     \n",
    "    if os.path.isfile(os.path.join(dwca_occurrence_df_path,\n",
    "                                   str(i_taxon_key) + \".csv\")): \n",
    "     \n",
    "        i_occ_df = pd.read_csv(os.path.join(dwca_occurrence_df_path,\n",
    "                                            str(i_taxon_key) + \".csv\"))\n",
    "        total_occ = len(i_occ_df)\n",
    "        \n",
    "        print(f\"Downloading for {species_name}\", flush=True) \n",
    "    else:\n",
    "        print(f\"No occurrence csv file found for {species_name}, taxon key {i_taxon_key}\")\n",
    "        continue\n",
    "    \n",
    "    # creating hierarchical folder structure for image storage\n",
    "    if not os.path.isdir(write_location):\n",
    "        try:\n",
    "            os.makedirs(write_location)\n",
    "        except:\n",
    "            print(f\"Could not create the directory for {write_location}\", flush=True)\n",
    "            continue\n",
    "        \n",
    "    image_count = 0\n",
    "    meta_data = {} \n",
    "\n",
    "    if total_occ != 0:\n",
    "        for idx, row in i_occ_df.iterrows():\n",
    "            obs_id = row[\"id\"]\n",
    "\n",
    "            # check occurrence entry in media dataframe\n",
    "            try:\n",
    "                media_entry = media_df.loc[media_df[\"coreid\"] == obs_id]\n",
    "\n",
    "                if not media_entry.empty:\n",
    "                \n",
    "                    if len(media_entry) > 1:  # multiple images for an observation\n",
    "                        media_entry = media_entry.iloc[0, :]\n",
    "                        image_url = media_entry[\"identifier\"]\n",
    "                    else:\n",
    "                        image_url = media_entry[\"identifier\"].item()\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e, flush=True)\n",
    "                continue\n",
    "\n",
    "            # download image\n",
    "            if os.path.isfile(write_location + \"/\" + str(obs_id) + \".jpg\"):\n",
    "                \n",
    "                image_count += 1\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    urllib.request.urlretrieve(\n",
    "                        image_url, write_location + \"/\" + str(obs_id) + \".jpg\"\n",
    "                    )\n",
    "                    image_count += 1\n",
    "                    # m_data = fetch_meta_data(row)\n",
    "                    # meta_data[str(obs_id) + \".jpg\"] = m_data\n",
    "                except:\n",
    "                    print(f\"Error downloading {image_url}\")\n",
    "                    continue\n",
    "\n",
    "            if image_count >= max_data_sp:\n",
    "                break\n",
    "\n",
    "        # with open(write_location + \"/\" + \"meta_data.json\", \"w\") as outfile:\n",
    "        #     json.dump(meta_data, outfile)\n",
    "        print(f\"Downloading complete for {species_name} with {image_count} images.\",\n",
    "              flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif_download_standalone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
