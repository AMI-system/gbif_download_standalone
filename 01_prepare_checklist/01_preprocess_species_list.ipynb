{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the species lists\n",
    "\n",
    "Short script to preprocess the species checklist.\n",
    "Will be modified for each incoming species checklist, depending on what must be done. \n",
    "\n",
    "The aim is to transform the column names of the checklist, so that: \n",
    "- The column with species name is called \"species_name_provided\"\n",
    "- The column with the authority is called \"authority_name_provided\". If such column doesn't exist, it should be created and left blank.\n",
    "- The authority column is formatted as \"Lastname, year\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, n, output_dir, list_name):\n",
    "    split_size = len(df) // n\n",
    "    for i in range(n):\n",
    "        start_idx = i * split_size\n",
    "        # Ensure the last part includes any remaining rows\n",
    "        end_idx = (i + 1) * split_size if i < n - 1 else len(df)\n",
    "        df_part = df.iloc[start_idx:end_idx]\n",
    "        file_path = os.path.join(output_dir, f\"{list_name}-preprocessed-part{i + 1}.csv\")\n",
    "        df_part.to_csv(file_path, index=False)\n",
    "        print(f\"Saved part {i + 1} to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Costa Rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"costarica-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                 sep=',', encoding='latin-1')\n",
    "\n",
    "df.columns = ['Family', 'Genus', 'Species', 'Subspecies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "\n",
    "df[\"authority_name_provided\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the column names to remove [] and ()\n",
    "df['authority_name_provided'] = df['authority_name_provided'].replace('[\\(\\)\\[\\]]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costa Rica list was too long for the API call. So had to split in 3 parts:\n",
    "split_dataframe(df, n=3, \n",
    "                output_dir=\"../species_checklists\", \n",
    "                list_name=checklist_name)\n",
    "# # Determine the split indices\n",
    "# split1 = len(df) // 3\n",
    "# split2 = 2 * split1\n",
    "\n",
    "# # Split the DataFrame into three parts\n",
    "# df1 = df.iloc[:split1]\n",
    "# df2 = df.iloc[split1:split2]\n",
    "# df3 = df.iloc[split2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the three parts to separate CSV files\n",
    "# df1.to_csv(os.path.join(\"../species_checklists/\", \n",
    "#                        checklist_name+\"-preprocessed-part1.csv\"),\n",
    "#           index=False)\n",
    "# df2.to_csv(os.path.join(\"../species_checklists/\", \n",
    "#                        checklist_name+\"-preprocessed-part2.csv\"),\n",
    "#           index=False)\n",
    "# df3.to_csv(os.path.join(\"../species_checklists/\", \n",
    "#                        checklist_name+\"-preprocessed-part3.csv\"),\n",
    "#           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file\n",
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## For UK moths \n",
    "\n",
    "This file is in a different format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"uksi-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                 sep=',', encoding='latin-1')\n",
    "\n",
    "df[\"Genus\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"taxon\"].fillna('')\n",
    "\n",
    "df[\"authority_name_provided\"] = df['preferred_authority'].replace('[\\(\\)\\[\\]]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Thailand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"thailand-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                sep=',', encoding='latin-1')\n",
    "\n",
    "#df.columns=['Superfamily', 'Family', 'Genus', 'Species']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['scientific_name'].str.split().str.len() > 2, 'scientific_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates in the scientific_name column\n",
    "df = df.drop_duplicates(subset='scientific_name')\n",
    "\n",
    "# only keep rows where the scientific_name is two words or more and keep the first two\n",
    "df = df[df['scientific_name'].str.split().str.len() > 1]\n",
    "df['scientific_name'] = df['scientific_name'].str.split().str[:2].str.join(' ')\n",
    "\n",
    "#df = df[['scientific_name', 'taxon_id']]\n",
    "df['Species']  = df['scientific_name']\n",
    "df['Genus']  = df['taxon_genus_name']\n",
    "\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Madagascar\n",
    "\n",
    "This comes from two sources: \n",
    "1. Moths from GBIF using the filter: \n",
    "    ```json\n",
    "    {\n",
    "    \"and\" : [\n",
    "        \"BasisOfRecord is one of (Human Observation, Specimen)\",\n",
    "        \"Country is Madagascar\",\n",
    "        \"OccurrenceStatus is Present\",\n",
    "        \"TaxonKey is Lepidoptera\"\n",
    "    ]\n",
    "    }\n",
    "    ```\n",
    "2. From Wikipedia: https://en.wikipedia.org/wiki/List_of_moths_of_Madagascar\n",
    "\n",
    "### 1. From GBIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "# Read the species checklist\n",
    "checklist_name = \"madagascar-moths\"\n",
    "\n",
    "mad_df1 = pd.read_csv(os.path.join(\"../species_checklists\",\n",
    "                            checklist_name+\"1.csv\"),\n",
    "                sep='\\t', encoding='latin-1')\n",
    "\n",
    "mad_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_df1 = mad_df1.loc[mad_df1['order'] == 'Lepidoptera', ]\n",
    "\n",
    "# create a column made up from the third word in column onwards\n",
    "mad_df1['Authority'] = mad_df1['scientificName'].str.split().str[2:].str.join(' ')\n",
    "\n",
    "mad_df1[\"species_name_provided\"] = mad_df1[\"genus\"].fillna('') + \" \" + mad_df1[\"species\"].fillna('')\n",
    "mad_df1[\"authority_name_provided\"] = mad_df1['Authority']\n",
    "\n",
    "mad_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_to_csv(wikipedia_url):\n",
    "    # Send a request to the Wikipedia page\n",
    "    response = requests.get(wikipedia_url)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the sections containing species information\n",
    "    family_sections = soup.find_all('h2')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop through each family section to extract species\n",
    "    for family_section in family_sections:\n",
    "        # Find the family name\n",
    "        family_name_tag = family_section.find('span', class_='mw-headline')\n",
    "        if not family_name_tag:\n",
    "            continue\n",
    "        family_name = family_name_tag.get_text()\n",
    "\n",
    "        # Skip any 'h3' subheadings\n",
    "        next_node = family_section.find_next_sibling()\n",
    "        while next_node and next_node.name != 'h2':\n",
    "            if next_node.name == 'div' and 'columns' in next_node.get('class', []):\n",
    "                for column in next_node.find_all('div', recursive=False):\n",
    "                    for li in column.find_all('li'):\n",
    "                        species_name = li.get_text().strip()\n",
    "                        # Keep only the first two words in the species name\n",
    "                        species_name = ' '.join(species_name.split()[:2])\n",
    "                        data.append({'Family': family_name, 'Species': species_name})\n",
    "            elif next_node.name == 'ul':\n",
    "                for li in next_node.find_all('li'):\n",
    "                    species_name = li.get_text().strip()\n",
    "                    # Keep only the first two words in the species name\n",
    "                    species_name = ' '.join(species_name.split()[:2])\n",
    "                    data.append({'Family': family_name, 'Species': species_name})\n",
    "            next_node = next_node.find_next_sibling()\n",
    "\n",
    "    # Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia URL for the moth species by family\n",
    "wikipedia_url = 'https://en.wikipedia.org/wiki/List_of_moths_of_Madagascar'\n",
    "\n",
    "mad_df2 = scrape_wikipedia_to_csv(wikipedia_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_df2['Genus'] = ''\n",
    "mad_df2['Authority'] = ''\n",
    "\n",
    "mad_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df and mad_df2\n",
    "mad_df2 = mad_df2[['Family', 'Genus', 'Species', 'Authority']]\n",
    "\n",
    "mad_df1 = mad_df1[['family', 'genus', 'species', 'Authority']]\n",
    "mad_df1.columns = mad_df2.columns\n",
    "\n",
    "df = pd.concat([mad_df1, mad_df2], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "# remove duplicated rows based on family, genus and species\n",
    "df = df.drop_duplicates(subset=['Family', 'Genus', 'Species'])\n",
    "\n",
    "# remove rows with missing species names\n",
    "df = df.dropna(subset=['Species'])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataframe(df=df, n=5, output_dir=\"../species_checklists/\", list_name=checklist_name)\n",
    "\n",
    "df.to_csv(os.path.join(\"../species_checklists/\",\n",
    "                    checklist_name+\"-preprocessed.csv\"),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Anguilla\n",
    "\n",
    "List provided by David Roy on 21/5/24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"anguilla-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\",\n",
    "                            checklist_name+\".csv\"),\n",
    "                sep=',', encoding='latin-1')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Genus\"] = \"\"\n",
    "\n",
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = \"\"\n",
    "\n",
    "df = df[['Family', 'Subfamily', 'Species', 'Genus', 'GBIF accepted name', 'species_name_provided', 'authority_name_provided']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_conda_env2 (Conda)",
   "language": "python",
   "name": "sys_kg_conda_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
