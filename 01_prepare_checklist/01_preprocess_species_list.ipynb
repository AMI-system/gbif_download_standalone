{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the species lists\n",
    "\n",
    "Short script to preprocess the species checklist.\n",
    "Will be modified for each incoming species checklist, depending on what must be done. \n",
    "\n",
    "The aim is to transform the column names of the checklist, so that: \n",
    "- The column with species name is called \"species_name_provided\"\n",
    "- The column with the authority is called \"authority_name_provided\". If such column doesn't exist, it should be created and left blank.\n",
    "- The authority column is formatted as \"Lastname, year\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, n, output_dir, list_name):\n",
    "    split_size = len(df) // n\n",
    "    for i in range(n):\n",
    "        start_idx = i * split_size\n",
    "        # Ensure the last part includes any remaining rows\n",
    "        end_idx = (i + 1) * split_size if i < n - 1 else len(df)\n",
    "        df_part = df.iloc[start_idx:end_idx]\n",
    "        file_path = os.path.join(output_dir, f\"{list_name}-preprocessed-part{i + 1}.csv\")\n",
    "        df_part.to_csv(file_path, index=False)\n",
    "        print(f\"Saved part {i + 1} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_to_csv(url):\n",
    "    # Send an HTTP GET request to fetch the content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check for request errors\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all <div> elements with class \"mw-heading mw-heading2\"\n",
    "    families = soup.find_all(\"div\", class_=\"mw-heading2\")\n",
    "\n",
    "    # Dictionary to store each heading and its corresponding list items\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    # Loop through each heading and capture the associated bullet points\n",
    "    for family in families:\n",
    "        # Get the heading text\n",
    "        family_text = family.get_text(strip=True).replace('[edit]', '')\n",
    "        \n",
    "        if family_text in ['Contents', 'References', 'See also']:\n",
    "            continue\n",
    "\n",
    "        # Find the next <ul> element (the bullet list after the heading)\n",
    "        bullet_list = family.find_next(\"ul\")\n",
    "\n",
    "        # Collect list items if a <ul> is found\n",
    "        items = []\n",
    "        if bullet_list:\n",
    "            auth = []\n",
    "            species = []\n",
    "            for li in bullet_list.find_all(\"li\"):\n",
    "\n",
    "                spec = [x.get_text(strip=True).strip() for x in li.find_all(\"a\")]\n",
    "                \n",
    "                if spec == []: \n",
    "                    spec = ['formatting error']\n",
    "                    spec_auth = ['formatting error']\n",
    "                else:\n",
    "                    spec = [spec[0]]\n",
    "                    spec_auth = [li.get_text(strip=True).replace(str(spec[0]), ' ').split('â€”', 1)[-1].strip().strip(\"()\")]\n",
    "                    species = species + spec\n",
    "\n",
    "                    if spec_auth == []: \n",
    "                        spec_auth = ['formatting error']\n",
    "                    \n",
    "                    auth = auth + spec_auth\n",
    "                    \n",
    "                    if len(auth) != len(species):\n",
    "                        print(spec)\n",
    "                    \n",
    "\n",
    "\n",
    "        df_dict = {'Family': [family_text] * len(auth), 'Genus': [''] * len(auth), 'Species': species, 'Authority': auth}\n",
    "        # print(len(df_dict['Family']), len(df_dict['Genus']), len(df_dict['Species']), len(df_dict['Authority']))\n",
    "        fam_df = pd.DataFrame(df_dict)\n",
    "        data = pd.concat([data, fam_df])\n",
    "\n",
    "    print(data)\n",
    "    data = data.loc[data['Species'] != \"formatting error\", ]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will want to remove all butterflies from the lists. These are the butterfly families:\n",
    "butterfly_families = ['Papilionidae', 'Nymphalidae', 'Pieridae', 'Lycaenidae', 'Riodinidae', 'Hesperiidae']\n",
    "\n",
    "def remove_butterflies(df, family_column='Family'):\n",
    "    og_count = df.shape[0]\n",
    "    print(f'Currently {og_count} species')\n",
    "    df = df[~df[family_column].isin(butterfly_families)]\n",
    "    print(f'Now {df.shape[0]} species, {og_count - df.shape[0]} butterfly species removed.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Costa Rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"costarica-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                 sep=',', encoding='latin-1')\n",
    "\n",
    "df.columns = ['Family', 'Genus', 'Species', 'Subspecies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "\n",
    "df[\"authority_name_provided\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the column names to remove [] and ()\n",
    "df['authority_name_provided'] = df['authority_name_provided'].replace('[\\(\\)\\[\\]]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_butterflies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costa Rica list was too long for the API call. So had to split in 3 parts:\n",
    "split_dataframe(df, n=3, \n",
    "                output_dir=\"../species_checklists\", \n",
    "                list_name=checklist_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## For UK moths \n",
    "\n",
    "This file is in a different format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"uksi-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                 sep=',', encoding='latin-1')\n",
    "\n",
    "df[\"Genus\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"taxon\"].fillna('')\n",
    "\n",
    "df[\"authority_name_provided\"] = df['preferred_authority'].replace('[\\(\\)\\[\\]]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_butterflies(df, 'family_taxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Thailand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"thailand-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\", checklist_name+\".csv\"),\n",
    "                sep=',', encoding='latin-1')\n",
    "\n",
    "#df.columns=['Superfamily', 'Family', 'Genus', 'Species']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['scientific_name'].str.split().str.len() > 2, 'scientific_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates in the scientific_name column\n",
    "df = df.drop_duplicates(subset='scientific_name')\n",
    "\n",
    "# only keep rows where the scientific_name is two words or more and keep the first two\n",
    "df = df[df['scientific_name'].str.split().str.len() > 1]\n",
    "df['scientific_name'] = df['scientific_name'].str.split().str[:2].str.join(' ')\n",
    "\n",
    "#df = df[['scientific_name', 'taxon_id']]\n",
    "df['Species']  = df['scientific_name']\n",
    "df['Genus']  = df['taxon_genus_name']\n",
    "\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_butterflies(df, 'taxon_family_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Madagascar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comes from two sources: \n",
    "1. Moths from GBIF using the filter: \n",
    "    ```json\n",
    "    {\n",
    "    \"and\" : [\n",
    "        \"BasisOfRecord is one of (Human Observation, Specimen)\",\n",
    "        \"Country is Madagascar\",\n",
    "        \"OccurrenceStatus is Present\",\n",
    "        \"TaxonKey is Lepidoptera\"\n",
    "    ]\n",
    "    }\n",
    "    ```\n",
    "2. From Wikipedia: https://en.wikipedia.org/wiki/List_of_moths_of_Madagascar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. From GBIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"madagascar-moths\"\n",
    "\n",
    "mad_df1 = pd.read_csv(os.path.join(\"../species_checklists\",\n",
    "                            checklist_name+\"1.csv\"),\n",
    "                sep='\\t', encoding='latin-1')\n",
    "\n",
    "mad_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_df1 = mad_df1.loc[mad_df1['order'] == 'Lepidoptera', ]\n",
    "\n",
    "# create a column made up from the third word in column onwards\n",
    "mad_df1['Authority'] = mad_df1['scientificName'].str.split().str[2:].str.join(' ')\n",
    "\n",
    "mad_df1[\"species_name_provided\"] = mad_df1[\"genus\"].fillna('') + \" \" + mad_df1[\"species\"].fillna('')\n",
    "mad_df1[\"authority_name_provided\"] = mad_df1['Authority']\n",
    "\n",
    "mad_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. From Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia URL for the moth species by family\n",
    "wikipedia_url = 'https://en.wikipedia.org/wiki/List_of_moths_of_Madagascar'\n",
    "\n",
    "# mad_df2 = scrape_wikipedia_to_csv(wikipedia_url)\n",
    "mad_df2 = scrape_wikipedia_to_csv(wikipedia_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df and mad_df2\n",
    "mad_df2 = mad_df2[['Family', 'Genus', 'Species', 'Authority']]\n",
    "\n",
    "mad_df1 = mad_df1[['family', 'genus', 'species', 'Authority']]\n",
    "mad_df1.columns = mad_df2.columns\n",
    "\n",
    "df = pd.concat([mad_df1, mad_df2], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "# remove duplicated rows based on family, genus and species\n",
    "df = df.drop_duplicates(subset=['Family', 'Genus', 'Species'])\n",
    "\n",
    "# remove rows with missing species names\n",
    "df = df.dropna(subset=['Species'])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_butterflies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataframe(df=df, n=5, output_dir=\"../species_checklists/\", list_name=checklist_name)\n",
    "\n",
    "df.to_csv(os.path.join(\"../species_checklists/\",\n",
    "                    checklist_name+\"-preprocessed.csv\"),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Anguilla\n",
    "\n",
    "List provided by David Roy on 21/5/24.\n",
    "Updated list on 24/10/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist\n",
    "checklist_name = \"anguilla-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\",\n",
    "                            checklist_name+\".csv\"),\n",
    "                sep=',', encoding='latin-1')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update = pd.read_csv(os.path.join(\"../species_checklists\",\n",
    "                            checklist_name+\"_update.csv\"),\n",
    "                sep=',', encoding='latin-1')\n",
    "\n",
    "df_update[\"Genus\"] = \"\"\n",
    "df_update[\"Family\"] = \"\"\n",
    "df_update[\"Subfamily\"] = \"\"\n",
    "df_update[\"GBIF accepted name\"] = \"\"\n",
    "\n",
    "df_update[\"species_name_provided\"] = df_update[\"Genus\"].fillna('') + \" \" + df_update[\"Species\"].fillna('')\n",
    "df_update[\"authority_name_provided\"] = \"\"\n",
    "\n",
    "df_update.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Genus\"] = \"\"\n",
    "\n",
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = \"\"\n",
    "\n",
    "df = df[['Family', 'Subfamily', 'Species', 'Genus', 'GBIF accepted name', 'species_name_provided', 'authority_name_provided']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two lists\n",
    "df_combined = pd.concat([df, df_update[list(df.columns)]])\n",
    "\n",
    "df_combined.loc[df_combined['species_name_provided'].str.contains('sp\\\\.'), 'species_name_provided'] = df_combined.loc[df_combined['species_name_provided'].str.contains('sp\\\\.'), 'species_name_provided'].str.replace(' sp.', '')\n",
    "\n",
    "\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined.shape)\n",
    "\n",
    "df_combined = df_combined.drop_duplicates(subset='Species', keep=\"first\")\n",
    "print(df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = remove_butterflies(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(os.path.join(\"../species_checklists/\", \n",
    "                       checklist_name+\"-preprocessed.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Kenya and Uganda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GBIF download\n",
    "\n",
    "From: https://www.gbif.org/occurrence/download?continent=AFRICA&country=KE&country=UG&taxon_key=797&advanced=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist from GBIF\n",
    "ku_df1 = pd.read_csv(os.path.join(\"../species_checklists\", \"kenya-uganda-gbif-moths.tsv\"),\n",
    "                sep='\\t', encoding='latin-1')\n",
    "\n",
    "# create a column made up from the third word in column onwards\n",
    "ku_df1['Authority'] = ku_df1['scientificName'].str.split().str[2:].str.join(' ')\n",
    "\n",
    "ku_df1[\"species_name_provided\"] = ku_df1[\"genus\"].fillna('') + \" \" + ku_df1[\"species\"].fillna('')\n",
    "ku_df1[\"authority_name_provided\"] = ku_df1['Authority']\n",
    "ku_df1['Source'] = 'gbif'\n",
    "\n",
    "ku_df1 = ku_df1[['family', 'genus', 'species', 'Authority', 'Source']]\n",
    "\n",
    "ku_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### From Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya_url = 'https://en.wikipedia.org/wiki/List_of_moths_of_Kenya'\n",
    "uganda_url = 'https://en.wikipedia.org/wiki/List_of_moths_of_Uganda'\n",
    "\n",
    "kenya_df_wiki = scrape_wikipedia_to_csv(kenya_url)\n",
    "uganda_df_wiki = scrape_wikipedia_to_csv(uganda_url)\n",
    "\n",
    "ku_df2 = pd.concat([kenya_df_wiki, uganda_df_wiki], ignore_index=True)\n",
    "ku_df2['Source'] = 'wiki'\n",
    "ku_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ku_df1.columns = ku_df2.columns\n",
    "df = pd.concat([ku_df1, ku_df2], ignore_index=True)\n",
    "\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = df['Authority']\n",
    "df['Subfamily'] = \"\"\n",
    "df[\"GBIF accepted name\"] = df[\"Species\"].fillna('')\n",
    "\n",
    "\n",
    "df = df[['Family', 'Subfamily', 'Species', 'Genus', 'GBIF accepted name', 'species_name_provided', 'authority_name_provided']]\n",
    "\n",
    "df = remove_butterflies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_name = 'kenya_uganda-gbif-moths'\n",
    "df.to_csv(os.path.join(\"../species_checklists/\",\n",
    "                    checklist_name+\"-preprocessed.csv\"),\n",
    "        index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Japan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GBIF download\n",
    "\n",
    "From: https://www.gbif.org/occurrence/download?continent=ASIA&country=JA&taxon_key=797&advanced=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist from GBIF\n",
    "jp_df1 = pd.read_csv(os.path.join(\"../species_checklists\", \"japan-gbif-moths.tsv\"),\n",
    "                sep='\\t', encoding='latin-1')\n",
    "\n",
    "# create a column made up from the third word in column onwards\n",
    "jp_df1['Authority'] = jp_df1['scientificName'].str.split().str[2:].str.join(' ')\n",
    "\n",
    "jp_df1[\"species_name_provided\"] = jp_df1[\"genus\"].fillna('') + \" \" + jp_df1[\"species\"].fillna('')\n",
    "jp_df1[\"authority_name_provided\"] = jp_df1['Authority']\n",
    "jp_df1['Source'] = 'gbif'\n",
    "jp_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### From Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_urls = ['https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Noctuoidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Bombycoidea-Geometroidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Pyraloidea-Drepanoidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Choreutoidea-Thyridoidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Zygaenoidea-Tortricoidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Gelechioidea)', \n",
    "             'https://en.wikipedia.org/wiki/List_of_moths_of_Japan_(Micropterigoidea-Yponomeutoidea)'] #'https://en.wikipedia.org/wiki/List_of_moths_of_Japan'\n",
    "\n",
    "jp_df2 = pd.DataFrame()\n",
    "\n",
    "for url in japan_urls: \n",
    "    print(url)\n",
    "\n",
    "\n",
    "    japan_df_wiki = scrape_wikipedia_to_csv(url)\n",
    "\n",
    "    jp_df2 = pd.concat([jp_df2, japan_df_wiki], ignore_index=True)\n",
    "\n",
    "jp_df2['Source'] = 'wiki'\n",
    "jp_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Jenna's list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://listmj.mothprog.com/list.html'\n",
    "\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "families, genera, species_list = [], [], []\n",
    "\n",
    "current_family = None\n",
    "current_genus = None\n",
    "\n",
    "# Loop through each element in the parsed HTML\n",
    "for tag in soup.find_all(True):\n",
    "    if 'family' in tag.get(\"class\", []):\n",
    "        # Update the current family\n",
    "        current_family = tag.find(\"span\", class_=\"highername\").get_text(strip=True) \n",
    "    elif 'genus' in tag.get(\"class\", []):\n",
    "        # Update the current genus\n",
    "        if tag.find(\"span\", class_=\"genusname\") is not None:\n",
    "            current_genus = tag.find(\"span\", class_=\"genusname\").get_text(strip=True)\n",
    "        else: \n",
    "            current_genus = 'undefined'\n",
    "    elif 'species' in tag.get(\"class\", []):\n",
    "        # Treat anything else as a species if within a family and genus\n",
    "        if tag.find(\"span\", class_=\"sciname\") is not None:\n",
    "            species_name = tag.find(\"span\", class_=\"sciname\").get_text(strip=True)   # take species name before any additional text\n",
    "        else:\n",
    "            species_name = 'Undefined: ' + tag.get_text(strip=True)\n",
    "        \n",
    "        families.append(current_family)\n",
    "        genera.append(current_genus)\n",
    "        species_list.append(species_name)\n",
    "\n",
    "# Create DataFrame\n",
    "jp_df3 = pd.DataFrame({\n",
    "    \"Family\": families,\n",
    "    \"Genus\": genera,\n",
    "    \"Species\": species_list\n",
    "})\n",
    "\n",
    "jp_df3['Authority'] = ''\n",
    "jp_df3['Source'] = 'List-MJ'\n",
    "\n",
    "jp_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine df1, df2 and df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_df1 = jp_df1[['family', 'genus', 'species', 'Authority', 'Source']]\n",
    "jp_df2 = jp_df2[['Family', 'Genus', 'Species', 'Authority', 'Source']]\n",
    "jp_df3 = jp_df3[['Family', 'Genus', 'Species', 'Authority', 'Source']]\n",
    "jp_df1.columns = jp_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([jp_df1, jp_df2, jp_df3], ignore_index=True)\n",
    "print(df['Source'].value_counts())\n",
    "\n",
    "# remove duplicated rows based on family, genus and species\n",
    "df = df.drop_duplicates(subset=['Family', 'Genus', 'Species'], keep='last')\n",
    "\n",
    "# remove rows with missing species names\n",
    "df = df.dropna(subset=['Species'])\n",
    "\n",
    "df = remove_butterflies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = df['Authority']\n",
    "df['Subfamily'] = \"\"\n",
    "df[\"GBIF accepted name\"] = df[\"Species\"].fillna('')\n",
    "\n",
    "df = df[['Family', 'Subfamily', 'Species', 'Genus', 'GBIF accepted name', 'species_name_provided', 'authority_name_provided']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[df['Species'].notnull()]\n",
    "print(df.shape)\n",
    "df = df[df['Genus'] != \"undefined\"]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_name = \"japan-moths\"\n",
    "df.to_csv(os.path.join(\"../species_checklists/\",\n",
    "                    checklist_name+\"-preprocessed.csv\"),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GBIF download\n",
    "\n",
    "From: https://www.gbif.org/occurrence/download?continent=AFRICA&country=NG&taxon_key=797&advanced=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the species checklist from GBIF\n",
    "ng_df1 = pd.read_csv(os.path.join(\"../species_checklists\", \"nigeria-gbif-moths.tsv\"),\n",
    "                sep='\\t', encoding='latin-1')\n",
    "\n",
    "# create a column made up from the third word in column onwards\n",
    "ng_df1['Authority'] = ng_df1['scientificName'].str.split().str[2:].str.join(' ')\n",
    "\n",
    "ng_df1[\"species_name_provided\"] = ng_df1[\"genus\"].fillna('') + \" \" + ng_df1[\"species\"].fillna('')\n",
    "ng_df1[\"authority_name_provided\"] = ng_df1['Authority']\n",
    "ng_df1['Source'] = 'gbif'\n",
    "ng_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### From Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nigeria_url = 'https://en.wikipedia.org/wiki/List_of_moths_of_Nigeria'\n",
    "\n",
    "ng_df2 = scrape_wikipedia_to_csv(nigeria_url)\n",
    "\n",
    "ng_df2['Source'] = 'wiki'\n",
    "ng_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine df1 and df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_df2 = ng_df2[['Family', 'Genus', 'Species', 'Authority', 'Source']]\n",
    "ng_df1 = ng_df1[['family', 'genus', 'species', 'Authority', 'Source']]\n",
    "ng_df1.columns = ng_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ng_df1, ng_df2], ignore_index=True)\n",
    "print(df['Source'].value_counts())\n",
    "\n",
    "# remove duplicated rows based on family, genus and species\n",
    "df = df.drop_duplicates(subset=['Family', 'Genus', 'Species'], keep='first')\n",
    "\n",
    "# remove rows with missing species names\n",
    "df = df.dropna(subset=['Species'])\n",
    "\n",
    "df = remove_butterflies(df)\n",
    "\n",
    "print(df['Source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costa rica column names\n",
    "df[\"species_name_provided\"] = df[\"Genus\"].fillna('') + \" \" + df[\"Species\"].fillna('')\n",
    "df[\"authority_name_provided\"] = df['Authority']\n",
    "df['Subfamily'] = \"\"\n",
    "df[\"GBIF accepted name\"] = df[\"Species\"].fillna('')\n",
    "\n",
    "\n",
    "df = df[['Family', 'Subfamily', 'Species', 'Genus', 'GBIF accepted name', 'species_name_provided', 'authority_name_provided']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_name = \"nigeria-moths\"\n",
    "df.to_csv(os.path.join(\"../species_checklists/\",\n",
    "                    checklist_name+\"-preprocessed.csv\"),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_conda_env2 (Conda)",
   "language": "python",
   "name": "sys_kg_conda_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
