{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicated species and those not on GBIF\n",
    "\n",
    "Short script that takes the species checklist and removed any duplicate species entries.\n",
    "\n",
    "If also removes entries not found on GBIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_duplicates(duplicates):\n",
    "    # Lets inspect cases where duplication is not caused by synonyms\n",
    "    duplicated_no_syn = duplicates.loc[duplicates['status']!='SYNONYM', ]\n",
    "    duplicated_no_syn[duplicated_no_syn.duplicated(subset='accepted_taxon_key', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_remove_duplicated(checklist_name):\n",
    "    df = pd.read_csv(os.path.join(\"../species_checklists\",checklist_name+\"-keys.csv\"))\n",
    "\n",
    "    # save not found entries to a new file\n",
    "    error_df = df[df[\"accepted_taxon_key\"] == -1]\n",
    "    error_df.to_csv(os.path.join(\"../species_checklists/failed_searches/failed-\"+checklist_name+\"-searches.csv\"), index=False)\n",
    "\n",
    "    \n",
    "    # Remove not available species\n",
    "    mask = df[\"accepted_taxon_key\"] != -1\n",
    "    df = df[mask]\n",
    "\n",
    "    df['authority_name_provided'] = df['authority_name_provided'].str.strip(\"()\")\n",
    "\n",
    "    # in most cases the duplication arises due to synonyms so lets order by that\n",
    "    df = df.sort_values(by=['status', 'authority_name_provided'])\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = df[df.duplicated(subset='accepted_taxon_key', keep=False)]\n",
    "    df_unique = df.drop_duplicates(subset='accepted_taxon_key', keep='first')\n",
    "\n",
    "    df_unique.to_csv(os.path.join(\"../species_checklists/\",checklist_name+\"-keys-nodup.csv\"), index=False)\n",
    "\n",
    "    print(\"Duplicate Rows:\")\n",
    "    display(duplicates)\n",
    "\n",
    "    print(\"duplicates not caused by synonyms:\")\n",
    "    inspect_df = df[df['accepted_taxon_key'].isin(duplicates['accepted_taxon_key'])]\n",
    "    display(inspect_df.sort_values(by=['accepted_taxon_key']))\n",
    "\n",
    "    return [duplicates, df_unique, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_and_remove_duplicated(\"japan-moths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_and_remove_duplicated(\"costarica-moths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_and_remove_duplicated(\"madagascar-moths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_and_remove_duplicated(\"kenya-uganda-moths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_and_remove_duplicated(\"nigeria-moths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
