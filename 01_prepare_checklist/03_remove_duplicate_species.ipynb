{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rmeove duplicated species and those not on GBIF\n",
    "\n",
    "Short script that takes the species checklist and removed any duplicate species entries.\n",
    "\n",
    "If also removes entries not found on GBIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the species checklist\n",
    "checklist_name = \"thailand-moths\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"../species_checklists\",checklist_name+\"-keys.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not available species\n",
    "mask = df[\"accepted_taxon_key\"] != -1\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in most cases the duplication arises due to synonyms so lets order by that\n",
    "df = df.sort_values(by=['status'])\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = df[df.duplicated(subset='accepted_taxon_key', keep=False)]\n",
    "\n",
    "# Printing duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets inspect cases where duplication is not caused by synonyms\n",
    "duplicated_no_syn = duplicates.loc[duplicates['status']!='SYNONYM', ]\n",
    "duplicated_no_syn[duplicated_no_syn.duplicated(subset='accepted_taxon_key', keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are flagged as subspecies in the input file so fine to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df_unique = df.drop_duplicates(subset='accepted_taxon_key', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file\n",
    "df_unique.to_csv(os.path.join(\"../species_checklists/\",checklist_name+\"-keys-nodup.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_conda_env2 (Conda)",
   "language": "python",
   "name": "sys_kg_conda_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
