{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "home_dir = os.getcwd()\n",
    "\n",
    "# data_dir = \"/bask/homes/r/rybf4168/vjgo8416-amber/data/gbif-species-trainer-AMI-fork\"\n",
    "data_dir = \"/Users/lbokeria/Documents/projects/gbif-species-trainer-data\"\n",
    "\n",
    "species_checklist_path = os.path.join(home_dir,\"species_checklists\",\"uksi-moths-keys-nodup-small.csv\")\n",
    "\n",
    "dwca_occurrence_df_path = os.path.join(data_dir,\"occurrence_dataframes\")\n",
    "\n",
    "dwca_multimedia_df_path = os.path.join(data_dir,\"dwca_files\",\"multimedia_lepidoptera.csv\")\n",
    "\n",
    "output_location_path = os.path.join(data_dir,\"gbif_images\",\"sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the multimedia file\n",
    "media_df = pd.read_csv(dwca_multimedia_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read species list\n",
    "moth_data = pd.read_csv(species_checklist_path)\n",
    "\n",
    "taxon_keys = list(moth_data[\"accepted_taxon_key\"])\n",
    "taxon_keys = [int(taxon) for taxon in taxon_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_meta_data(data: pd.DataFrame):\n",
    "    \"\"\"returns the relevant metadata for a GBIF observation\"\"\"\n",
    "\n",
    "    fields = [\n",
    "        \"decimalLatitude\",\n",
    "        \"decimalLongitude\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"species\",\n",
    "        \"acceptedScientificName\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"datasetName\",\n",
    "        \"taxonID\",\n",
    "        \"acceptedTaxonKey\",\n",
    "        \"lifeStage\",\n",
    "        \"basisOfRecord\",\n",
    "    ]\n",
    "\n",
    "    meta_data = {}\n",
    "\n",
    "    for field in fields:\n",
    "        if pd.isna(data[field]):\n",
    "            meta_data[field] = \"NA\"\n",
    "        else:\n",
    "            meta_data[field] = data[field]\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, define a function that manages the parallel execution:\n",
    "def download_images_concurrently(taxon_keys,use_parallel,n_workers):\n",
    "    \n",
    "    begin = time.time()\n",
    "\n",
    "    \n",
    "    if use_parallel:\n",
    "        with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "\n",
    "            # You can use the executor to parallelize your function call:\n",
    "            results = list(executor.map(fetch_image_data, taxon_keys))\n",
    "    \n",
    "    else:\n",
    "       \n",
    "        for i_taxon_key in taxon_keys:\n",
    "            print(f\"Calling for {i_taxon_key}\")\n",
    "            fetch_image_data(i_taxon_key)\n",
    "   \n",
    "\n",
    "    end = time.time()\n",
    "            \n",
    "    print(\"Finished downloading for the given list! Time taken:\", \n",
    "          round(end - begin), \n",
    "          \"seconds\",\n",
    "          flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger():\n",
    "    \n",
    "    # Specify the directory where you want to save the log files\n",
    "    log_dir = \"log_files\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # Use the timestamp string to create a unique filename for the log file\n",
    "    timestamp    = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_filename = os.path.join(log_dir, f'download_log_{timestamp}.log')\n",
    "    \n",
    "    # Get the root logger\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # If logger has handlers, clear them\n",
    "    for handler in logger.handlers[:]:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Configure the logger\n",
    "    logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_data(i_taxon_key: int):\n",
    "    global skip_non_adults, max_data_sp\n",
    "    \n",
    "    # get taxa information specific to the species\n",
    "    taxon_data = moth_data[moth_data[\"accepted_taxon_key\"] == i_taxon_key]\n",
    "\n",
    "    family_name         = taxon_data[\"family_name\"].item()\n",
    "    genus_name          = taxon_data[\"genus_name\"].item()\n",
    "    species_name        = taxon_data[\"gbif_species_name\"].item()\n",
    "    write_location      = os.path.join(output_location_path,family_name,genus_name,species_name)\n",
    "\n",
    "    # Does meta_data exist for this species?\n",
    "    if os.path.isfile(os.path.join(write_location,\"meta_data.json\")):\n",
    "        # Load it \n",
    "        with open(os.path.join(write_location,\"meta_data.json\")) as file:\n",
    "            species_meta_data = json.load(file)\n",
    "    else:\n",
    "        # Creat it\n",
    "        species_meta_data = {}\n",
    "\n",
    "\n",
    "    # Read the occurrence dataframe\n",
    "    if os.path.isfile(os.path.join(dwca_occurrence_df_path,\n",
    "                                    str(i_taxon_key) + \".csv\")): \n",
    "        i_occ_df = pd.read_csv(os.path.join(dwca_occurrence_df_path,\n",
    "                                            str(i_taxon_key) + \".csv\"))\n",
    "        total_occ = len(i_occ_df)\n",
    "        print(f\"Downloading for {species_name}\", flush=True) \n",
    "    else:\n",
    "        logger.warning(\n",
    "            f\"No occurrence csv file found for {species_name}, taxon key {i_taxon_key}\"\n",
    "            )\n",
    "        return\n",
    "\n",
    "    # creating hierarchical folder structure for image storage\n",
    "    if not os.path.isdir(write_location):\n",
    "        try:\n",
    "            os.makedirs(write_location)\n",
    "        except:\n",
    "            print(f\"Could not create the directory for {write_location}\", flush=True)\n",
    "            return\n",
    "        \n",
    "    image_count = 0\n",
    "\n",
    "    if total_occ != 0:\n",
    "        # print(f\"{species_name} has some occurrences\")\n",
    "        \n",
    "        for idx, row in i_occ_df.iterrows():\n",
    "            \n",
    "            if skip_non_adults:\n",
    "                \n",
    "                if (not pd.isna(row[\"lifeStage\"])) & (row[\"lifeStage\"] != \"Adult\"):\n",
    "                    \n",
    "                    # print(\"Life stage is\", row[\"lifeStage\"], \"skipping...\")\n",
    "                \n",
    "                    continue\n",
    "            \n",
    "            obs_id = row[\"id\"]\n",
    "\n",
    "            # Is there already an image, or is corrupt or a thumbnail, or broken URL?\n",
    "            if len(species_meta_data) != 0:\n",
    "                \n",
    "                if str(obs_id)+\".jpg\" in species_meta_data.keys():\n",
    "                    \n",
    "                    if species_meta_data[str(obs_id)+\".jpg\"][\"image_is_downloaded\"]:\n",
    "                        # print(f\"{obs_id} already downloaded\")\n",
    "                        image_count += 1\n",
    "                        \n",
    "                        if image_count >= max_data_sp:\n",
    "                            break            \n",
    "                        else:           \n",
    "                            continue    \n",
    "                    \n",
    "                    if (\n",
    "                        (not species_meta_data[str(obs_id)+\".jpg\"][\"image_url_works\"]) or \n",
    "                        species_meta_data[str(obs_id)+\".jpg\"][\"image_is_corrupted\"] or \n",
    "                        species_meta_data[str(obs_id)+\".jpg\"][\"image_is_thumbnail\"]\n",
    "                    ):\n",
    "                        # print(f\"{obs_id} already downloaded/corrupt/thumbnail/broken URL\")\n",
    "                        continue\n",
    "            \n",
    "            # check occurrence entry in media dataframe\n",
    "            try:\n",
    "                media_entry = media_df.loc[media_df[\"coreid\"] == obs_id]\n",
    "\n",
    "                if not media_entry.empty:\n",
    "                    # print(f\"{species_name} has some media\")\n",
    "                          \n",
    "                    if len(media_entry) > 1:  # multiple images for an observation\n",
    "                        media_entry = media_entry.iloc[0, :]\n",
    "                        image_url = media_entry[\"identifier\"]\n",
    "                    else:\n",
    "                        image_url = media_entry[\"identifier\"].item()\n",
    "                else:\n",
    "                    \n",
    "                    # print(f\"{species_name} has NO media\")\n",
    "                    continue\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e, flush=True)\n",
    "                continue\n",
    "\n",
    "            # download image\n",
    "            try:\n",
    "                urllib.request.urlretrieve(\n",
    "                    image_url, write_location + \"/\" + str(obs_id) + \".jpg\"\n",
    "                )\n",
    "                image_count += 1\n",
    "                url_works = True\n",
    "                image_downloaded = True\n",
    "                # m_data = fetch_meta_data(row)\n",
    "                # meta_data[str(obs_id) + \".jpg\"] = m_data\n",
    "            except:\n",
    "                print(f\"Error downloading URL: '{image_url}'\")\n",
    "                url_works = False\n",
    "                image_downloaded = False\n",
    "            \n",
    "            # Get meta data for this occurrence\n",
    "            occ_meta_data = fetch_meta_data(row)\n",
    "            occ_meta_data[\"image_is_downloaded\"] = image_downloaded\n",
    "            occ_meta_data[\"image_url_works\"] = url_works\n",
    "            occ_meta_data[\"image_is_corrupted\"] = \"\"\n",
    "            occ_meta_data[\"image_is_thumbnail\"] = \"\"\n",
    "            \n",
    "            species_meta_data[str(obs_id) + \".jpg\"] = occ_meta_data\n",
    "            \n",
    "            if image_count >= max_data_sp:\n",
    "                break\n",
    "            \n",
    "        # Dump metadata\n",
    "        with open(write_location + \"/\" + \"meta_data.json\", \"w\") as outfile:\n",
    "            json.dump(species_meta_data, outfile)            \n",
    "            \n",
    "    print(f\"Downloading complete for {species_name} with {image_count} images.\",\n",
    "            flush=True)\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading for Synanthedon andrenaeformis\n",
      "Downloading for Pyropteron chrysidiformis\n",
      "Downloading for Synanthedon flaviventris\n",
      "3124704355 already downloadedDownloading for Synanthedon culiciformis\n",
      "\n",
      "Downloading for Pennisetia hylaeiformis\n",
      "Downloading for Bembecia ichneumoniformis\n",
      "Downloading for Sesia bembeciformis\n",
      "Downloading for Paranthrene tabaniformis\n",
      "Downloading for Synanthedon formicaeformis\n",
      "2808494876 already downloaded\n",
      "2330570120 already downloaded/corrupt/thumbnail/broken URL\n",
      "Downloading for Sesia apiformis\n",
      "3970558267 already downloaded3915783447 already downloaded\n",
      "3950155336 already downloaded\n",
      "3944851316 already downloaded\n",
      "3944849310 already downloaded\n",
      "3944851319 already downloaded\n",
      "3944850329 already downloaded\n",
      "3915790320 already downloaded\n",
      "3950170319 already downloaded\n",
      "3950169312 already downloaded\n",
      "3944854345 already downloaded\n",
      "3950149301 already downloaded\n",
      "3944851327 already downloaded\n",
      "3944837348 already downloaded\n",
      "3915787433 already downloaded\n",
      "3981016817 already downloaded\n",
      "3950169316 already downloaded\n",
      "3915785331 already downloaded\n",
      "3950152319 already downloaded\n",
      "\n",
      "3437293320 already downloaded\n",
      "3970562252 already downloaded\n",
      "3437296657 already downloaded\n",
      "3437466311 already downloaded\n",
      "3437477327 already downloaded\n",
      "3437477328 already downloaded\n",
      "3970558970 already downloaded\n",
      "3970561264 already downloaded\n",
      "3437523643 already downloaded\n",
      "3437292327 already downloaded\n",
      "3970557974 already downloaded\n",
      "3437396405 already downloaded\n",
      "3970563228 already downloaded\n",
      "3970561961 already downloaded\n",
      "3970563965 already downloaded\n",
      "3970556977 already downloaded\n",
      "3970558969 already downloaded\n",
      "3970559970 already downloaded\n",
      "3437466315 already downloaded\n",
      "3970562976 already downloaded\n",
      "3437451460 already downloaded\n",
      "3970556978 already downloaded\n",
      "3437477330 already downloaded\n",
      "3970559228 already downloaded\n",
      "3970559971 already downloaded\n",
      "2294512838 already downloaded\n",
      "3330471171 already downloaded\n",
      "3437236400 already downloaded\n",
      "3437238562 already downloaded\n",
      "3437238563 already downloaded\n",
      "3437237434 already downloaded\n",
      "3970559227 already downloaded\n",
      "3944858328 already downloaded\n",
      "3448223877 already downloaded\n",
      "3437236401 already downloaded\n",
      "3437236402 already downloaded\n",
      "3970563967 already downloaded\n",
      "3981015684 already downloaded\n",
      "3981036830 already downloaded\n",
      "3981029627 already downloaded\n",
      "3981015758 already downloaded\n",
      "3981036601 already downloaded\n",
      "3981013350 already downloaded\n",
      "3981009374 already downloaded\n",
      "3981016767 already downloaded\n",
      "3981003490 already downloaded\n",
      "3981009382 already downloaded\n",
      "3981028441 already downloaded\n",
      "3981031431 already downloaded\n",
      "3981023765 already downloaded\n",
      "3981030621 already downloaded\n",
      "3981023719 already downloaded\n",
      "3981022494 already downloaded\n",
      "3981030732 already downloaded\n",
      "3981016596 already downloaded\n",
      "3981009386 already downloaded\n",
      "3981003715 already downloaded\n",
      "3437396400 already downloaded\n",
      "3437396401 already downloaded\n",
      "3437396402 already downloaded\n",
      "3970559969 already downloaded\n",
      "3970560226 already downloaded\n",
      "3437451458 already downloaded\n",
      "3437451459 already downloaded\n",
      "3437258198 already downloaded\n",
      "3437295041 already downloaded\n",
      "3970561964 already downloaded\n",
      "3437293326 already downloaded\n",
      "3437338953 already downloaded\n",
      "3437455255 already downloaded\n",
      "3970557978 already downloaded3857510973 already downloaded\n",
      "\n",
      "3437296662 already downloaded\n",
      "3437342189 already downloaded\n",
      "3437396403 already downloaded\n",
      "3437396404 already downloaded\n",
      "3437421284 already downloaded\n",
      "3970558968 already downloaded\n",
      "3970561229 already downloaded\n",
      "3437466317 already downloaded\n",
      "3437466318 already downloaded\n",
      "3970560976 already downloaded\n",
      "3437416396 already downloaded\n",
      "3437416397 already downloaded\n",
      "3437490171 already downloaded\n",
      "3437440433 already downloaded\n",
      "3437440434 already downloaded\n",
      "3117804315 already downloaded\n",
      "4006712894 already downloaded\n",
      "3118497751 already downloaded\n",
      "3874079175 already downloaded\n",
      "3325496351 already downloaded\n",
      "3447937585 already downloaded\n",
      "1965066531 already downloaded\n",
      "3723890114 already downloaded\n",
      "3728150898 already downloaded\n",
      "3915789413 already downloaded\n",
      "3915783306 already downloaded\n",
      "3915794305 already downloaded\n",
      "3915794479 already downloaded\n",
      "3915794506 already downloaded\n",
      "3915789380 already downloaded\n",
      "3915787305 already downloaded\n",
      "3915805336 already downloaded\n",
      "3915788304 already downloaded\n",
      "3915790328 already downloaded\n",
      "3915804368 already downloaded\n",
      "3915790304 already downloaded\n",
      "3915804349 already downloaded\n",
      "3915784305 already downloaded\n",
      "3915784420 already downloaded\n",
      "3915804364 already downloaded\n",
      "3915793334 already downloaded\n",
      "3915785350 already downloaded\n",
      "3915794457 already downloaded\n",
      "3915808316 already downloaded\n",
      "3915787466 already downloaded\n",
      "3915798366 already downloaded\n",
      "3915789332 already downloaded\n",
      "3915808323 already downloaded\n",
      "3915804398 already downloaded\n",
      "3915808425 already downloaded\n",
      "3915789337 already downloaded\n",
      "3915789328 already downloaded\n",
      "3915811361 already downloaded\n",
      "3915790372 already downloaded\n",
      "3915787483 already downloaded\n",
      "3889187356 already downloaded\n",
      "3415538234 already downloaded\n",
      "2814268979 already downloaded\n",
      "1319449059 already downloaded\n",
      "3915790474 already downloaded\n",
      "3915783833 already downloaded\n",
      "3915801391 already downloaded\n",
      "3915795410 already downloaded\n",
      "3915812626 already downloaded\n",
      "3915796425 already downloaded\n",
      "3915787855 already downloaded\n",
      "1339274274 already downloaded/corrupt/thumbnail/broken URL\n",
      "3915793327 already downloaded\n",
      "3915812331 already downloaded\n",
      "3925418577 already downloaded\n",
      "3915781320 already downloaded\n",
      "3915784379 already downloaded\n",
      "3859255234 already downloaded\n",
      "2874025454 already downloaded\n",
      "3873363404 already downloaded\n",
      "3873771594 already downloaded\n",
      "3321208781 already downloaded\n",
      "3981053498 already downloaded\n",
      "3981028409 already downloaded\n",
      "3981007732 already downloaded\n",
      "3981020619 already downloaded\n",
      "3981014431 already downloaded\n",
      "3981005541 already downloaded\n",
      "3981020491 already downloaded\n",
      "3981010479 already downloaded\n",
      "3981018725 already downloaded\n",
      "3981018774 already downloaded\n",
      "3981036744 already downloaded\n",
      "3456795064 already downloaded\n",
      "3320902314 already downloaded\n",
      "2874017391 already downloaded\n",
      "4076069346 already downloaded\n",
      "2269300890 already downloaded\n",
      "3944863322 already downloaded\n",
      "3944853306 already downloaded\n",
      "3944851321 already downloaded\n",
      "3944858318 already downloaded\n",
      "3944852337 already downloaded\n",
      "3944854315 already downloaded\n",
      "3944849306 already downloaded\n",
      "3944856317 already downloaded\n",
      "3944844314 already downloaded\n",
      "3944859304 already downloaded\n",
      "3944844318 already downloaded\n",
      "3944850331 already downloaded\n",
      "3313497330 already downloaded\n",
      "3981018617 already downloaded\n",
      "3981023632 already downloaded\n",
      "Downloading complete for Synanthedon andrenaeformis with 25 images.\n",
      "Downloading for Synanthedon myopaeformis\n",
      "2802606192 already downloaded\n",
      "3859879648 already downloaded\n",
      "3892348939 already downloaded\n",
      "3388022459 already downloaded/corrupt/thumbnail/broken URL\n",
      "3950149312 already downloaded\n",
      "3950157308 already downloaded\n",
      "3981010489 already downloaded\n",
      "3950141343 already downloaded\n",
      "3950160302 already downloaded\n",
      "3981053577 already downloaded\n",
      "3981011388 already downloaded\n",
      "3981023723 already downloaded\n",
      "3950166324 already downloaded\n",
      "3981031420 already downloaded\n",
      "3950158301 already downloaded\n",
      "3950143326 already downloaded\n",
      "3950167314 already downloaded\n",
      "3950143335 already downloaded\n",
      "3981026797 already downloaded\n",
      "3302253712 already downloaded\n",
      "3031694688 already downloaded\n",
      "Downloading complete for Pyropteron chrysidiformis with 25 images.\n",
      "Downloading for Synanthedon scoliaeformis\n",
      "1670070500 already downloaded\n",
      "3437236403 already downloaded\n",
      "3437279265 already downloaded\n",
      "3437279269 already downloaded\n",
      "3437293322 already downloaded\n",
      "3437237435 already downloaded\n",
      "3437296658 already downloaded\n",
      "3437467754 already downloaded\n",
      "3970560227 already downloaded\n",
      "3437466313 already downloaded\n",
      "3437416398 already downloaded\n",
      "3970557975 already downloaded\n",
      "3970557976 already downloaded\n",
      "3970561962 already downloaded\n",
      "3437528046 already downloaded\n",
      "3437511230 already downloaded\n",
      "3314229116 already downloaded\n",
      "2609187348 already downloaded\n",
      "3718845010 already downloaded\n",
      "3727916173 already downloaded\n",
      "Downloading complete for Synanthedon culiciformis with 25 images.\n",
      "Downloading for Synanthedon spheciformis\n",
      "3437238564 already downloaded\n",
      "3437237437 already downloaded\n",
      "3437416399 already downloaded\n",
      "3970562977 already downloaded\n",
      "3970562978 already downloaded\n",
      "3970556980 already downloaded\n",
      "3970556979 already downloaded\n",
      "3437576224 already downloaded\n",
      "3437468527 already downloaded\n",
      "3970564224 already downloaded\n",
      "3437292323 already downloaded\n",
      "3859982060 already downloaded\n",
      "2330527181 already downloaded/corrupt/thumbnail/broken URL\n",
      "2838053523 already downloaded\n",
      "2843700741 already downloaded\n",
      "3722772696 already downloaded\n",
      "2836914877 already downloaded\n",
      "3915802323 already downloaded\n",
      "3915784873 already downloaded\n",
      "3915804552 already downloaded\n",
      "3915788400 already downloaded\n",
      "Downloading complete for Bembecia ichneumoniformis with 25 images.\n",
      "Downloading for Synanthedon tipuliformis\n",
      "3437236404 already downloaded\n",
      "3437279264 already downloaded\n",
      "3970558971 already downloaded\n",
      "3437293318 already downloaded\n",
      "3437293319 already downloaded\n",
      "3437237436 already downloaded\n",
      "3970559972 already downloaded\n",
      "3437296653 already downloaded\n",
      "3437296654 already downloaded\n",
      "3970558972 already downloaded\n",
      "3437466308 already downloaded\n",
      "3437482150 already downloaded\n",
      "3970556981 already downloaded\n",
      "3437455251 already downloaded\n",
      "3437477326 already downloaded\n",
      "3437487229 already downloaded\n",
      "3437523641 already downloaded\n",
      "3437565137 already downloaded\n",
      "3437292324 already downloaded\n",
      "2610953529 already downloaded\n",
      "Downloading complete for Synanthedon flaviventris with 25 images.\n",
      "Downloading for Synanthedon vespiformis\n",
      "3772502275 already downloaded\n",
      "4011699882 already downloaded\n",
      "2238775831 already downloaded\n",
      "3873004799 already downloaded\n",
      "3337902512 already downloaded\n",
      "3058641303 already downloaded/corrupt/thumbnail/broken URL\n",
      "3389088366 already downloaded/corrupt/thumbnail/broken URL\n",
      "2845375988 already downloaded\n",
      "3944863326 already downloaded\n",
      "3950143312 already downloaded\n",
      "3950150328 already downloaded\n",
      "3981020555 already downloaded\n",
      "3950139307 already downloaded\n",
      "3950170352 already downloaded\n",
      "3950141327 already downloaded\n",
      "3981018827 already downloaded\n",
      "3981018600 already downloaded\n",
      "3981005605 already downloaded\n",
      "3950151311 already downloaded\n",
      "3950150334 already downloaded\n",
      "3950150312 already downloaded\n",
      "3981016709 already downloaded\n",
      "Downloading complete for Synanthedon scoliaeformis with 25 images.\n",
      "Downloading complete for Synanthedon spheciformis with 25 images.\n",
      "Downloading complete for Synanthedon myopaeformis with 25 images.\n",
      "Downloading complete for Synanthedon vespiformis with 25 images.\n",
      "Downloading complete for Sesia bembeciformis with 25 images.\n",
      "Downloading complete for Synanthedon formicaeformis with 25 images.\n",
      "Error downloading URL: 'https://static.inaturalist.org/photos/29045553/original.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Setup logger\n",
    "setup_logger()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Start the run\n",
    "n_workers = 10\n",
    "use_parallel = True\n",
    "max_data_sp = 25\n",
    "skip_non_adults = True\n",
    "\n",
    "# Lastly, call the function with your taxon keys:\n",
    "download_images_concurrently(taxon_keys,use_parallel,n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif_download_standalone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
